"""Auto-split mixins for gateway MemoryMiddleware."""

import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from lib.common.logging import get_logger
from lib.memory.memory_v2 import CCBLightMemory
from lib.memory.registry import CCBRegistry
from lib.skills.skills_discovery import SkillsDiscoveryService

from .system_context import SystemContextBuilder

try:
    from lib.memory.heuristic_retriever import HeuristicRetriever, ScoredMemory
    HAS_HEURISTIC = True
except ImportError:
    HAS_HEURISTIC = False


logger = get_logger("gateway.middleware.memory")


class MemoryMiddlewareCoreMixin:
    """Mixin methods extracted from MemoryMiddleware."""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.memory = CCBLightMemory()
        self.registry = CCBRegistry()

        # åŠ è½½é…ç½®
        self.config = config or self._load_config()
        self.enabled = self.config.get("memory", {}).get("enabled", True)
        self.auto_inject = self.config.get("memory", {}).get("auto_inject", True)
        self.auto_record = self.config.get("memory", {}).get("auto_record", True)
        self.max_injected = self.config.get("memory", {}).get("max_injected_memories", 5)
        self.inject_system_context = self.config.get("memory", {}).get("inject_system_context", True)

        # é¢„åŠ è½½ç³»ç»Ÿä¸Šä¸‹æ–‡ï¼ˆSkillsã€MCPã€Providersï¼‰
        self.system_context = SystemContextBuilder()

        # ğŸ†• åˆå§‹åŒ– Skills Discovery Service
        self.skills_discovery = SkillsDiscoveryService()
        self.enable_skill_discovery = self.config.get("skills", {}).get("auto_discover", True)

        # v1.1 shared knowledge hook (injected by GatewayServer)
        self._shared_knowledge = None

        # ğŸ†• v2.0: å¯å‘å¼æ£€ç´¢å™¨
        self.heuristic_retriever = None
        self.use_heuristic = self.config.get("memory", {}).get("use_heuristic_retrieval", True)
        if HAS_HEURISTIC and self.use_heuristic:
            try:
                self.heuristic_retriever = HeuristicRetriever()
                logger.info(f"Heuristic retriever initialized")
            except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
                logger.info(f"Heuristic retriever init error: {e}")

        logger.info(f"Initialized (enabled={self.enabled}, heuristic={self.heuristic_retriever is not None})")
        logger.info(f"System context preloaded: {self.system_context.get_stats()}")
        logger.info(f"Skills discovery: {self.enable_skill_discovery}")

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path.home() / ".ccb" / "gateway_config.json"

        if config_file.exists():
            with open(config_file) as f:
                return json.load(f)

        # é»˜è®¤é…ç½®
        return {
            "memory": {
                "enabled": True,
                "auto_inject": True,
                "auto_record": True,
                "max_injected_memories": 5,
                "inject_system_context": True,  # æ–°å¢ï¼šæ³¨å…¥ç³»ç»Ÿä¸Šä¸‹æ–‡
                "injection_strategy": "recent_plus_relevant",
                "use_heuristic_retrieval": True  # v2.0: ä½¿ç”¨å¯å‘å¼æ£€ç´¢
            },
            "skills": {
                "auto_discover": True,  # ğŸ†• è‡ªåŠ¨å‘ç°ç›¸å…³æŠ€èƒ½
                "recommend_skills": True,  # ğŸ†• æ¨èæŠ€èƒ½ç»™ç”¨æˆ·
                "max_recommendations": 3  # ğŸ†• æœ€å¤šæ¨èæŠ€èƒ½æ•°
            },
            "recommendation": {
                "enabled": True,
                "auto_switch_provider": False,
                "confidence_threshold": 0.7
            }
        }

    async def pre_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯·æ±‚å‰å¤„ç†ï¼ˆPre-Request Hookï¼‰

        åŠŸèƒ½ï¼š
        1. æå–ä»»åŠ¡å…³é”®è¯
        2. æœç´¢ç›¸å…³è®°å¿†
        3. æ¨èæœ€ä½³ Provider
        4. æ³¨å…¥ä¸Šä¸‹æ–‡åˆ° prompt
        """
        if not self.enabled or not self.auto_inject:
            return request

        provider = request.get("provider")
        message = request.get("message", "")
        user_id = request.get("user_id", "default")

        logger.info(f"Pre-request: provider={provider}, message_len={len(message)}")

        # 1. æå–ä»»åŠ¡å…³é”®è¯
        keywords = self._extract_keywords(message)
        logger.info(f"Extracted keywords: {keywords}")

        # ğŸ†• 1.5. Skills Discovery - å‘ç°ç›¸å…³æŠ€èƒ½
        skill_recommendations = None
        if self.enable_skill_discovery:
            try:
                skill_recommendations = self.skills_discovery.get_recommendations(message)
                if skill_recommendations['found']:
                    logger.info(f"{skill_recommendations['message']}")
            except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
                logger.info(f"Skills discovery error: {e}")

        # 2. æœç´¢ç›¸å…³è®°å¿† (v2.0: ä½¿ç”¨å¯å‘å¼æ£€ç´¢)
        relevant_memories = []
        heuristic_results = []  # v2.0: ä¿å­˜è¯„åˆ†ç»“æœ
        if keywords:
            try:
                if self.heuristic_retriever:
                    # v2.0: ä½¿ç”¨ HeuristicRetriever çš„ Î±R + Î²I + Î³T è¯„åˆ†
                    heuristic_results = self.heuristic_retriever.retrieve(
                        " ".join(keywords),
                        limit=self.max_injected,
                        request_id=request.get("request_id"),
                        track_access=True
                    )
                    # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
                    relevant_memories = [
                        {
                            "id": m.memory_id,
                            "message_id": m.memory_id,
                            "provider": m.provider,
                            "question": "",
                            "answer": m.content[:300] if m.role == 'assistant' else m.content[:300],
                            "timestamp": m.timestamp,
                            "relevance_score": m.relevance_score,
                            "importance_score": m.importance_score,
                            "recency_score": m.recency_score,
                            "final_score": m.final_score
                        }
                        for m in heuristic_results
                    ]
                    logger.info(f"Heuristic search: found {len(relevant_memories)} memories")
                else:
                    # å›é€€åˆ°åŸºæœ¬æœç´¢
                    relevant_memories = self.memory.search_conversations(
                        " ".join(keywords),
                        limit=self.max_injected
                    )
                    logger.info(f"Basic search: found {len(relevant_memories)} memories")
            except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
                logger.info(f"Search error: {e}")

        # 3. æ¨èæœ€ä½³ Providerï¼ˆå¦‚æœå¯ç”¨ï¼‰
        logger.info(f"Provider before recommendation: {provider}")
        recommendation_config = self.config.get("recommendation", {})
        if recommendation_config.get("enabled", True) and provider in ["auto", None]:
            logger.info(f"Entering recommendation logic (provider={provider})")
            try:
                recommendations = self.registry.recommend_provider(keywords)
                if recommendations:
                    recommended_provider = recommendations[0]["provider"]
                    reason = recommendations[0]["reason"]

                    logger.info(f"Recommended: {recommended_provider} ({reason})")

                    if recommendation_config.get("auto_switch_provider", False):
                        logger.info(f"Auto-switching provider: {provider} -> {recommended_provider}")
                        request["provider"] = recommended_provider
                        request["_recommendation"] = {
                            "provider": recommended_provider,
                            "reason": reason,
                            "auto_switched": True
                        }
            except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
                logger.info(f"Recommendation error: {e}")

        # 4. æ³¨å…¥ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç³»ç»Ÿä¸Šä¸‹æ–‡å’Œç›¸å…³è®°å¿†ï¼‰
        try:
            context_parts = []

            # 4a. æ³¨å…¥é¢„åŸ‹çš„ç³»ç»Ÿä¸Šä¸‹æ–‡ï¼ˆSkillsã€MCPã€Providersï¼‰
            if self.inject_system_context:
                system_ctx = self.system_context.get_relevant_context(
                    keywords,
                    provider or request.get("provider", "unknown")
                )
                if system_ctx:
                    context_parts.append(system_ctx)
                    logger.info(f"System context injected")

            # 4b. æ³¨å…¥ç›¸å…³è®°å¿†
            if relevant_memories:
                memory_ctx = self._format_memory_context(relevant_memories)
                if memory_ctx:
                    context_parts.append(memory_ctx)
                    logger.info(f"{len(relevant_memories)} memories injected")

            # ğŸ†• 4c. æ³¨å…¥æŠ€èƒ½æ¨èï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
            if skill_recommendations and skill_recommendations['found']:
                skills_ctx = self._format_skills_context(skill_recommendations)
                if skills_ctx:
                    context_parts.append(skills_ctx)
                    logger.info(f"Skills recommendations injected")

            # åˆå¹¶ä¸Šä¸‹æ–‡
            if context_parts:
                full_context = "\n\n".join(context_parts)

                # å¢å¼ºåŸå§‹æ¶ˆæ¯
                request["message"] = f"""# ç³»ç»Ÿä¸Šä¸‹æ–‡

{full_context}

---

# ç”¨æˆ·è¯·æ±‚
{message}
"""
                request["_memory_injected"] = True
                request["_memory_count"] = len(relevant_memories)
                request["_system_context_injected"] = self.inject_system_context
                request["_skills_recommended"] = bool(skill_recommendations and skill_recommendations['found'])

                # ğŸ†• Phase 1: è¿½è¸ªæ³¨å…¥è¯¦æƒ…ï¼ˆå¦‚æœæœ‰ request_idï¼‰
                request_id = request.get("request_id")
                if request_id:
                    self._track_injection(
                        request_id=request_id,
                        provider=provider,
                        original_message=message,
                        memories=relevant_memories,
                        skills=skill_recommendations,
                        system_context_injected=self.inject_system_context
                    )

        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
            logger.info(f"Context injection error: {e}")

        return request

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–ä»»åŠ¡å…³é”®è¯ï¼ˆv3: ä½¿ç”¨æœ¬åœ° LLM æå–è¯­ä¹‰å…³é”®è¯ï¼‰"""
        # å°è¯•ä½¿ç”¨ LLM æå–ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°æ­£åˆ™æå–
        try:
            return self._extract_keywords_with_llm(text)
        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
            logger.info(f"LLM extraction failed: {e}, fallback to regex")
            return self._extract_keywords_regex(text)

    def _extract_keywords_with_llm(self, text: str) -> List[str]:
        """
        ä½¿ç”¨ Ollama æ™ºèƒ½è·¯ç”±æå–å…³é”®è¯

        è·¯ç”±ç­–ç•¥ï¼š
        1. é¦–é€‰æœ¬åœ° qwen2.5:7bï¼ˆå¿«é€Ÿï¼Œæ— ç½‘ç»œä¾èµ–ï¼‰
        2. æœ¬åœ°è¶…æ—¶/å¤±è´¥ â†’ è‡ªåŠ¨åˆ‡æ¢äº‘ç«¯ deepseek-v3.1:671b-cloud
        3. äº‘ç«¯å¤±è´¥ â†’ å›é€€åˆ°æ­£åˆ™æå–
        """
        import requests
        import re

        # æ¸…ç†æ–‡æœ¬
        cleaned = re.sub(r'\s+', ' ', text).strip()

        # çŸ­æŸ¥è¯¢ç›´æ¥è¿”å›
        if len(cleaned) <= 10:
            return [cleaned]

        # æ„é€ æç¤ºè¯
        prompt = f"""ä»ä¸‹é¢çš„é—®é¢˜ä¸­æå–2-3ä¸ªæœ€æ ¸å¿ƒçš„å…³é”®è¯ï¼ˆåè¯æˆ–åè¯çŸ­è¯­ï¼‰ï¼Œç”¨é€—å·åˆ†éš”ã€‚
åªè¿”å›å…³é”®è¯ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚

é—®é¢˜ï¼š{cleaned}

å…³é”®è¯ï¼š"""

        # æ¨¡å‹è·¯ç”±é…ç½®
        models = [
            {
                'name': 'qwen2.5:7b',
                'timeout': 6,      # æœ¬åœ°æ¨¡å‹ 6 ç§’è¶…æ—¶ï¼ˆå†·å¯åŠ¨ ~5sï¼Œçƒ­è°ƒç”¨ <1sï¼‰
                'location': 'local'
            },
            {
                'name': 'deepseek-v3.1:671b-cloud',
                'timeout': 10,     # äº‘ç«¯æ¨¡å‹ 10 ç§’è¶…æ—¶
                'location': 'cloud'
            }
        ]

        last_error = None
        for model_config in models:
            model_name = model_config['name']
            timeout = model_config['timeout']
            location = model_config['location']

            try:
                response = requests.post(
                    'http://localhost:11434/api/generate',
                    json={
                        'model': model_name,
                        'prompt': prompt,
                        'stream': False,
                        'options': {
                            'temperature': 0.3,
                            'num_predict': 50
                        }
                    },
                    timeout=timeout
                )

                if response.status_code == 200:
                    result = response.json()
                    keywords_str = result.get('response', '').strip()

                    # è§£æå…³é”®è¯
                    keywords = []
                    raw_keywords = re.split(r'[,ï¼Œã€]', keywords_str)

                    for kw in raw_keywords:
                        cleaned_kw = re.sub(r'^[\d\.\sã€]+', '', kw.strip())
                        cleaned_kw = re.sub(r'[ã€‚ï¼ï¼Ÿ,.!?ã€]+$', '', cleaned_kw)
                        if cleaned_kw and len(cleaned_kw) >= 2:
                            keywords.append(cleaned_kw)

                    if keywords:
                        logger.info(f"LLM extracted ({location}:{model_name}): {keywords}")
                        return keywords[:5]

            except requests.exceptions.Timeout:
                logger.info(f"Ollama timeout ({timeout}s) for {location}:{model_name}")
                last_error = f"timeout:{model_name}"
                continue  # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
            except requests.exceptions.ConnectionError:
                logger.info(f"Ollama not running on localhost:11434")
                last_error = "connection_error"
                break  # Ollama æœåŠ¡æœªè¿è¡Œï¼Œç›´æ¥é€€å‡º
            except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
                logger.info(f"Ollama API error ({model_name}): {e}")
                last_error = str(e)
                continue  # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹

        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        raise Exception(f"LLM extraction failed, fallback to regex")

    def _extract_keywords_regex(self, text: str) -> List[str]:
        """æ­£åˆ™æå–å…³é”®è¯ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        import re

        # æ¸…ç†ï¼šç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
        cleaned = re.sub(r'\s+', ' ', text).strip()

        # ä¸­æ–‡åœç”¨è¯ï¼ˆç–‘é—®è¯å’ŒåŠ©è¯ï¼‰
        stop_words = {
            "çš„", "æ˜¯", "åœ¨", "æœ‰", "å’Œ", "äº†", "æˆ‘", "ä½ ", "ä»–", "å¥¹",
            "è¿™", "é‚£", "ä¸€ä¸ª", "æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "éœ€è¦",
            "å¯ä»¥", "è¿˜", "åˆšæ‰", "æåˆ°", "è€ƒè™‘", "å—", "å‘¢", "å§", "è¦",
            "ä¼š", "èƒ½", "å°†", "è¢«", "æŠŠ", "å¯¹", "ç»™", "è®©", "å‘", "ä»",
            "æ³¨æ„", "å…³æ³¨", "æ€è€ƒ", "æƒ³è¦", "çŸ¥é“", "äº†è§£", "å“ªäº›",
        }

        # æå– 3-4 å­—çš„ä¸­æ–‡åè¯ï¼ˆé€šå¸¸æ˜¯å®ä½“è¯ï¼‰
        # å¦‚ï¼š"è´­ç‰©è½¦"ã€"ç”µå•†ç½‘ç«™"ã€"Reactç»„ä»¶"
        chinese_keywords = re.findall(r'[\u4e00-\u9fff]{3,4}', cleaned)

        # æå–è‹±æ–‡å•è¯ï¼ˆ3å­—æ¯ä»¥ä¸Šï¼‰
        english_keywords = re.findall(r'\b[a-zA-Z]{3,}\b', cleaned.lower())

        # è¿‡æ»¤åœç”¨è¯
        keywords = []
        for word in chinese_keywords + english_keywords:
            if word not in stop_words and len(word) >= 2:
                keywords.append(word)

        # å»é‡
        seen = set()
        unique_keywords = []
        for k in keywords:
            if k not in seen:
                seen.add(k)
                unique_keywords.append(k)

        # å¦‚æœæå–åˆ°å…³é”®è¯ï¼Œè¿”å›å‰5ä¸ªæœ€é‡è¦çš„
        # å¦‚æœæ²¡æœ‰å…³é”®è¯ï¼Œè¿”å›æ¸…ç†åçš„åŸæ–‡ï¼ˆçŸ­æŸ¥è¯¢ï¼‰
        if unique_keywords:
            return unique_keywords[:5]
        else:
            # å¯¹äºçŸ­æŸ¥è¯¢ï¼ˆå¦‚"è´­ç‰©è½¦"ï¼‰ï¼Œç›´æ¥è¿”å›
            return [cleaned] if len(cleaned) <= 10 else []

