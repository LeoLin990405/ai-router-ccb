"""Auto-split mixins for gateway MemoryMiddleware."""

import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from lib.common.logging import get_logger
from lib.memory.memory_v2 import CCBLightMemory
from lib.memory.registry import CCBRegistry
from lib.skills.skills_discovery import SkillsDiscoveryService

from .system_context import SystemContextBuilder

try:
    from lib.memory.heuristic_retriever import HeuristicRetriever, ScoredMemory
    HAS_HEURISTIC = True
except ImportError:
    HAS_HEURISTIC = False


logger = get_logger("gateway.middleware.memory")


class MemoryMiddlewarePostMixin:
    """Mixin methods extracted from MemoryMiddleware."""

    async def post_response(self, request: Dict[str, Any], response: Dict[str, Any]):
        """
        å“åº”åŽå¤„ç†ï¼ˆPost-Response Hookï¼‰

        åŠŸèƒ½ï¼š
        1. è®°å½•å¯¹è¯
        2. æ›´æ–°ç»Ÿè®¡
        3. ï¼ˆå¯é€‰ï¼‰æå–å…³é”®äº‹å®ž
        """
        if not self.enabled or not self.auto_record:
            return

        try:
            provider = request.get("provider", "unknown")
            message = request.get("message", "")

            # ç§»é™¤æ³¨å…¥çš„ä¸Šä¸‹æ–‡ï¼Œåªä¿å­˜åŽŸå§‹é—®é¢˜
            if request.get("_memory_injected"):
                # æå–åŽŸå§‹é—®é¢˜ï¼ˆåœ¨ "# ç”¨æˆ·è¯·æ±‚" ä¹‹åŽï¼‰
                parts = message.split("# ç”¨æˆ·è¯·æ±‚")
                if len(parts) > 1:
                    message = parts[1].strip()

            response_text = response.get("response", "")

            metadata = {
                "model": request.get("model"),
                "latency_ms": response.get("latency_ms"),
                "tokens": response.get("tokens"),
                "memory_injected": request.get("_memory_injected", False),
                "memory_count": request.get("_memory_count", 0)
            }

            # è®°å½•å¯¹è¯
            self.memory.record_conversation(
                provider=provider,
                question=message,
                answer=response_text,
                metadata=metadata
            )

            logger.info(f"Conversation recorded: provider={provider}")

            # ðŸ†• è®°å½•æŠ€èƒ½ä½¿ç”¨ï¼ˆå¦‚æžœå“åº”ä¸­æåˆ°äº†æŠ€èƒ½ï¼‰
            if self.enable_skill_discovery:
                self._record_skill_usage(request, response)

            # v1.1: è‡ªåŠ¨å‘å¸ƒé«˜è´¨é‡å“åº”åˆ° Shared Knowledge
            await self._maybe_auto_publish(request, response)

            # æ›´æ–°ç»Ÿè®¡ï¼ˆç”¨äºŽæŽ¨èä¼˜åŒ–ï¼‰
            # self.registry.update_usage_stats(provider, metadata)

        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
            logger.info(f"Post-response error: {e}")

    def _format_memory_context(self, memories: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆv2.0: åŒ…å«è¯„åˆ†ä¿¡æ¯ï¼‰"""
        if not memories:
            return ""

        context_parts = ["## ðŸ’­ ç›¸å…³è®°å¿†"]

        for i, mem in enumerate(memories, 1):
            provider_name = mem.get("provider", "unknown")
            question = mem.get("question", "")[:100]
            answer = mem.get("answer", "")[:200]

            # v2.0: å¦‚æžœæœ‰è¯„åˆ†ï¼Œæ˜¾ç¤ºè¯„åˆ†ä¿¡æ¯
            score_info = ""
            if mem.get("final_score") is not None:
                score_info = f" (score: {mem['final_score']:.2f})"

            context_parts.append(f"{i}. [{provider_name}]{score_info} {question}")
            context_parts.append(f"   A: {answer}...")
            context_parts.append("")

        return "\n".join(context_parts)

    def _format_skills_context(self, recommendations: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æŠ€èƒ½æŽ¨èä¸Šä¸‹æ–‡ï¼ˆðŸ†• æ–°å¢žï¼‰"""
        if not recommendations or not recommendations.get('found'):
            return ""

        context_parts = ["## ðŸ› ï¸ ç›¸å…³æŠ€èƒ½æŽ¨è"]

        for skill in recommendations.get('skills', []):
            name = skill['name']
            description = skill['description']
            installed = skill['installed']
            relevance = skill['relevance_score']

            if installed:
                # å·²å®‰è£…çš„æŠ€èƒ½
                context_parts.append(
                    f"- **/{name}** (score: {relevance}) - {description}"
                )
                context_parts.append(f"  âœ“ å·²å®‰è£…ï¼Œå¯ç›´æŽ¥ä½¿ç”¨: `/{name}`")
            else:
                # æœªå®‰è£…çš„æŠ€èƒ½
                context_parts.append(
                    f"- **{name}** (score: {relevance}) - {description}"
                )
                context_parts.append(f"  âš ï¸ æœªå®‰è£…ï¼Œå»ºè®®å®‰è£…åŽä½¿ç”¨")

        return "\n".join(context_parts)

    def _format_context(
        self,
        memories: List[Dict[str, Any]],
        keywords: List[str],
        provider: str
    ) -> str:
        """æ ¼å¼åŒ–è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        return self._format_memory_context(memories)

    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–ä¸­é—´ä»¶ç»Ÿè®¡ä¿¡æ¯ (v2.0: åŒ…å«å¯å‘å¼æ£€ç´¢ç»Ÿè®¡)"""
        stats = {
            "enabled": self.enabled,
            "auto_inject": self.auto_inject,
            "auto_record": self.auto_record,
            "memory_stats": self.memory.get_stats(),
            "heuristic_enabled": self.heuristic_retriever is not None
        }

        # v2.0: æ·»åŠ å¯å‘å¼æ£€ç´¢ç»Ÿè®¡
        if self.heuristic_retriever:
            try:
                stats["heuristic_stats"] = self.heuristic_retriever.get_statistics()
            except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
                stats["heuristic_error"] = str(e)

        return stats

    def _record_skill_usage(self, request: Dict[str, Any], response: Dict[str, Any]):
        """è®°å½•æŠ€èƒ½ä½¿ç”¨æƒ…å†µï¼ˆðŸ†• æ–°å¢žï¼‰"""
        try:
            response_text = response.get("response", "")
            message = request.get("message", "")
            provider = request.get("provider", "unknown")

            # æ£€æµ‹å“åº”ä¸­æ˜¯å¦æåˆ°äº†æŠ€èƒ½ï¼ˆé€šè¿‡ /skill-name æ¨¡å¼ï¼‰
            import re
            skill_mentions = re.findall(r'/([a-z0-9\-]+)', response_text)

            if skill_mentions:
                keywords = " ".join(self._extract_keywords(message))

                for skill_name in skill_mentions:
                    # è®°å½•ä½¿ç”¨
                    self.skills_discovery.record_usage(
                        skill_name=skill_name,
                        task_keywords=keywords,
                        provider=provider,
                        success=True
                    )

                logger.info(f"Recorded skill usage: {skill_mentions}")

        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
            logger.info(f"Skill usage recording error: {e}")

    async def _maybe_auto_publish(self, request_data: Dict[str, Any], response_data: Dict[str, Any]) -> None:
        """Auto-publish high-quality responses to shared knowledge."""
        shared_service = getattr(self, "_shared_knowledge", None)
        if shared_service is None:
            return

        response_text = str(response_data.get("response", "") or "").strip()
        if not response_text or len(response_text) < 200:
            return

        has_code = "```" in response_text
        has_structure = response_text.count("\n") > 10
        if not (has_code or has_structure):
            return

        provider = str(request_data.get("provider", "unknown") or "unknown")
        message = str(request_data.get("message", "") or "")
        title = message[:120] if message else f"Auto insight from {provider}"

        category = "solution" if has_code else "learning"
        tags = self._extract_tags(message)

        metadata = {
            "auto_published": True,
            "provider": provider,
            "model": request_data.get("model"),
            "latency_ms": response_data.get("latency_ms"),
            "tokens": response_data.get("tokens"),
        }

        try:
            shared_service.publish(
                agent_id=f"{provider}-auto",
                category=category,
                title=title,
                content=response_text[:2000],
                tags=tags,
                source_request_id=request_data.get("request_id"),
                metadata=metadata,
            )
            logger.debug("Auto-published shared knowledge from provider %s", provider)
        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError):
            logger.debug("Auto-publish failed", exc_info=True)

    def _extract_tags(self, text: str) -> List[str]:
        """Extract compact keyword tags from text."""
        import re

        words = re.findall(r"\b[a-zA-Z]{3,15}\b", text.lower())
        stopwords = {
            "the",
            "and",
            "for",
            "this",
            "that",
            "with",
            "from",
            "have",
            "are",
            "was",
            "your",
            "into",
            "about",
            "when",
            "then",
        }

        tags: List[str] = []
        for word in words:
            if word in stopwords:
                continue
            if word not in tags:
                tags.append(word)
            if len(tags) >= 5:
                break

        return tags

    def _track_injection(
        self,
        request_id: str,
        provider: str,
        original_message: str,
        memories: List[Dict[str, Any]],
        skills: Optional[Dict[str, Any]],
        system_context_injected: bool
    ):
        """è¿½è¸ªè®°å¿†æ³¨å…¥è¯¦æƒ…ï¼ˆPhase 1: Transparencyï¼‰"""
        try:
            # æå–è®°å¿† IDs å’Œç›¸å…³æ€§åˆ†æ•°
            memory_ids = []
            relevance_scores = {}
            for mem in memories:
                mem_id = mem.get("id") or mem.get("message_id")
                if mem_id:
                    memory_ids.append(mem_id)
                    # å¦‚æžœæœ‰ç›¸å…³æ€§åˆ†æ•°
                    if mem.get("relevance_score"):
                        relevance_scores[mem_id] = mem.get("relevance_score")

            # æå–æŠ€èƒ½åç§°
            skill_names = []
            if skills and skills.get("found"):
                for skill in skills.get("skills", []):
                    skill_names.append(skill.get("name"))

            # ä½¿ç”¨ memory v2 è¿½è¸ª
            self.memory.v2.track_request_injection(
                request_id=request_id,
                provider=provider,
                original_message=original_message,
                injected_memory_ids=memory_ids,
                injected_skills=skill_names,
                injected_system_context=system_context_injected,
                relevance_scores=relevance_scores,
                metadata={
                    "memory_count": len(memories),
                    "skills_count": len(skill_names),
                    "system_context": system_context_injected
                }
            )

            logger.info(f"Tracked injection for {request_id}: "
                  f"{len(memory_ids)} memories, {len(skill_names)} skills")

        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
            logger.info(f"Injection tracking error: {e}")

    # ========================================================================
    # Discussion Memory (Phase 6)
    # ========================================================================

    async def post_discussion(
        self,
        session_id: str,
        topic: str,
        providers: List[str],
        summary: str = None,
        insights: List[Dict[str, Any]] = None,
        messages: List[Dict[str, Any]] = None
    ) -> Optional[str]:
        """Record a discussion to memory system (Phase 6)

        Args:
            session_id: Discussion session ID
            topic: Discussion topic
            providers: List of participating providers
            summary: Discussion summary
            insights: Extracted insights
            messages: Discussion messages

        Returns:
            observation_id if recorded, None otherwise
        """
        if not self.enabled or not self.auto_record:
            return None

        try:
            observation_id = self.memory.v2.record_discussion(
                session_id=session_id,
                topic=topic,
                providers=providers,
                summary=summary,
                insights=insights,
                messages=messages
            )

            logger.info(f"Discussion recorded: {session_id} -> {observation_id}")
            return observation_id

        except (RuntimeError, ValueError, TypeError, KeyError, AttributeError, OSError) as e:
            logger.info(f"Discussion recording error: {e}")
            return None

