#!/usr/bin/env python3
"""
CCB Memory Cloud Migration
æœ¬åœ°æ•°æ®åº“ â†’ äº‘ç«¯æ•°æ®åº“ è¿ç§»å·¥å…·
"""

import os
import sqlite3
import sys
from pathlib import Path
from typing import Literal

try:
    from lib.common.logging import get_logger
except ImportError:  # pragma: no cover - script mode
    try:
        from common.logging import get_logger  # type: ignore
    except ImportError:  # pragma: no cover - fallback
        import logging

        def get_logger(name: str):
            return logging.getLogger(name)


logger = get_logger("memory.cloud")


def _emit(message: str = "") -> None:
    sys.stdout.write(f"{message}\n")


class CCBCloudMigration:
    """äº‘ç«¯æ•°æ®åº“è¿ç§»å·¥å…·"""

    def __init__(self, cloud_type: Literal["firebase", "supabase", "planetscale"]):
        self.cloud_type = cloud_type
        self.local_db = Path.home() / ".ccb" / "ccb_memory.db"

        if cloud_type == "firebase":
            self._init_firebase()
        elif cloud_type == "supabase":
            self._init_supabase()
        elif cloud_type == "planetscale":
            self._init_planetscale()

    def _init_firebase(self):
        """åˆå§‹åŒ– Firebase"""
        try:
            import firebase_admin
            from firebase_admin import credentials, firestore

            cred_path = Path.home() / ".ccb" / "firebase-key.json"
            if not cred_path.exists():
                _emit("âŒ æœªæ‰¾åˆ° Firebase å‡­è¯æ–‡ä»¶: ~/.ccb/firebase-key.json")
                _emit("ğŸ“– è·å–å‡­è¯: https://console.firebase.google.com/")
                raise FileNotFoundError("missing ~/.ccb/firebase-key.json")

            cred = credentials.Certificate(str(cred_path))
            firebase_admin.initialize_app(cred)
            self.db = firestore.client()
            _emit("âœ… Firebase å·²è¿æ¥")

        except ImportError:
            _emit("âŒ è¯·å®‰è£…: pip3 install firebase-admin")
            raise

    def _init_supabase(self):
        """åˆå§‹åŒ– Supabase"""
        try:
            from supabase import create_client, Client

            url = os.environ.get("SUPABASE_URL")
            key = os.environ.get("SUPABASE_KEY")

            if not url or not key:
                _emit("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
                _emit("  export SUPABASE_URL='https://xxx.supabase.co'")
                _emit("  export SUPABASE_KEY='your-anon-key'")
                raise ValueError("SUPABASE_URL or SUPABASE_KEY missing")

            self.db: Client = create_client(url, key)
            _emit("âœ… Supabase å·²è¿æ¥")

        except ImportError:
            _emit("âŒ è¯·å®‰è£…: pip3 install supabase")
            raise

    def _init_planetscale(self):
        """åˆå§‹åŒ– PlanetScaleï¼ˆMySQLï¼‰"""
        try:
            import pymysql

            host = os.environ.get("PLANETSCALE_HOST")
            user = os.environ.get("PLANETSCALE_USER")
            password = os.environ.get("PLANETSCALE_PASSWORD")
            database = os.environ.get("PLANETSCALE_DATABASE")

            if not all([host, user, password, database]):
                _emit("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
                _emit("  export PLANETSCALE_HOST='xxx.psdb.cloud'")
                _emit("  export PLANETSCALE_USER='...'")
                _emit("  export PLANETSCALE_PASSWORD='...'")
                _emit("  export PLANETSCALE_DATABASE='...'")
                raise ValueError("PlanetScale env vars are incomplete")

            self.db = pymysql.connect(
                host=host,
                user=user,
                password=password,
                database=database,
                ssl={"ssl": True},
            )
            _emit("âœ… PlanetScale å·²è¿æ¥")

        except ImportError:
            _emit("âŒ è¯·å®‰è£…: pip3 install pymysql")
            raise

    def migrate_to_cloud(self, batch_size: int = 100, dry_run: bool = False):
        """
        è¿ç§»æœ¬åœ°æ•°æ®åˆ°äº‘ç«¯

        Args:
            batch_size: æ‰¹é‡ä¸Šä¼ å¤§å°
            dry_run: åªæµ‹è¯•ä¸ä¸Šä¼ 
        """
        if not self.local_db.exists():
            _emit("âŒ æœ¬åœ°æ•°æ®åº“ä¸å­˜åœ¨")
            return

        # è¯»å–æœ¬åœ°æ•°æ®
        conn = sqlite3.connect(self.local_db)
        cursor = conn.cursor()

        cursor.execute("SELECT COUNT(*) FROM conversations")
        total_count = cursor.fetchone()[0]

        _emit(f"\nğŸ“¦ å‡†å¤‡è¿ç§» {total_count} æ¡è®°å½•...")

        if dry_run:
            _emit("ğŸ” DRY RUN æ¨¡å¼ - ä¸ä¼šå®é™…ä¸Šä¼ ")

        cursor.execute(
            """
            SELECT id, timestamp, provider, question, answer, metadata, tokens
            FROM conversations
            ORDER BY id
        """
        )

        migrated = 0
        failed = 0

        while True:
            rows = cursor.fetchmany(batch_size)
            if not rows:
                break

            if dry_run:
                migrated += len(rows)
                _emit(f"  âœ“ æ¨¡æ‹Ÿè¿ç§» batch {migrated}/{total_count}")
                continue

            # ä¸Šä¼ åˆ°äº‘ç«¯
            try:
                if self.cloud_type == "firebase":
                    self._upload_firebase_batch(rows)
                elif self.cloud_type == "supabase":
                    self._upload_supabase_batch(rows)
                elif self.cloud_type == "planetscale":
                    self._upload_planetscale_batch(rows)

                migrated += len(rows)
                _emit(f"  âœ“ å·²è¿ç§» {migrated}/{total_count} ({migrated / total_count * 100:.1f}%)")

            except (RuntimeError, ValueError, TypeError, OSError, sqlite3.Error) as e:
                failed += len(rows)
                logger.warning("Batch upload failed: %s", e)
                _emit(f"  âœ— æ‰¹æ¬¡ä¸Šä¼ å¤±è´¥: {e}")

        conn.close()

        _emit(f"\n{'=' * 60}")
        _emit("âœ… è¿ç§»å®Œæˆ:")
        _emit(f"  æˆåŠŸ: {migrated}/{total_count}")
        if failed > 0:
            _emit(f"  å¤±è´¥: {failed}/{total_count}")

    def _upload_firebase_batch(self, rows):
        """æ‰¹é‡ä¸Šä¼ åˆ° Firebase"""
        batch = self.db.batch()

        for row in rows:
            doc_ref = self.db.collection("conversations").document(str(row[0]))
            batch.set(
                doc_ref,
                {
                    "timestamp": row[1],
                    "provider": row[2],
                    "question": row[3],
                    "answer": row[4],
                    "metadata": row[5],
                    "tokens": row[6],
                },
            )

        batch.commit()

    def _upload_supabase_batch(self, rows):
        """æ‰¹é‡ä¸Šä¼ åˆ° Supabase"""
        data = [
            {
                "id": row[0],
                "timestamp": row[1],
                "provider": row[2],
                "question": row[3],
                "answer": row[4],
                "metadata": row[5],
                "tokens": row[6],
            }
            for row in rows
        ]

        self.db.table("conversations").insert(data).execute()

    def _upload_planetscale_batch(self, rows):
        """æ‰¹é‡ä¸Šä¼ åˆ° PlanetScale"""
        cursor = self.db.cursor()

        cursor.executemany(
            """
            INSERT INTO conversations (id, timestamp, provider, question, answer, metadata, tokens)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE timestamp=VALUES(timestamp)
        """,
            rows,
        )

        self.db.commit()

    def verify_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        # æœ¬åœ°æ•°æ®ç»Ÿè®¡
        conn = sqlite3.connect(self.local_db)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*), provider FROM conversations GROUP BY provider")
        local_stats = dict(cursor.fetchall())
        conn.close()

        _emit("\nğŸ” éªŒè¯è¿ç§»ç»“æœ:")
        _emit(f"{'=' * 60}")
        _emit(f"{'Provider':<15} {'æœ¬åœ°':<10} {'äº‘ç«¯':<10} {'çŠ¶æ€'}")
        _emit(f"{'-' * 60}")

        # äº‘ç«¯æ•°æ®ç»Ÿè®¡
        if self.cloud_type == "firebase":
            for provider, local_count in local_stats.items():
                docs = self.db.collection("conversations").where("provider", "==", provider).stream()
                cloud_count = sum(1 for _ in docs)

                status = "âœ…" if cloud_count == local_count else "âŒ"
                _emit(f"{provider:<15} {local_count:<10} {cloud_count:<10} {status}")

        elif self.cloud_type == "supabase":
            for provider, local_count in local_stats.items():
                result = self.db.table("conversations").select("*", count="exact").eq("provider", provider).execute()
                cloud_count = result.count

                status = "âœ…" if cloud_count == local_count else "âŒ"
                _emit(f"{provider:<15} {local_count:<10} {cloud_count:<10} {status}")


def main():
    import sys

    if len(sys.argv) < 2:
        _emit(
            """
CCB Memory äº‘ç«¯è¿ç§»å·¥å…·

ç”¨æ³•:
  python3 memory_cloud.py <cloud-type> <command> [options]

äº‘ç«¯ç±»å‹:
  firebase      - Google Firebase Firestore
  supabase      - Supabase PostgreSQL
  planetscale   - PlanetScale MySQL

å‘½ä»¤:
  migrate       - å¼€å§‹è¿ç§»
  verify        - éªŒè¯è¿ç§»ç»“æœ
  dry-run       - æµ‹è¯•è¿ç§»ï¼ˆä¸ä¸Šä¼ ï¼‰

ç¤ºä¾‹:
  # è¿ç§»åˆ° Firebase
  python3 memory_cloud.py firebase migrate

  # æµ‹è¯•è¿ç§»
  python3 memory_cloud.py supabase dry-run

  # éªŒè¯ç»“æœ
  python3 memory_cloud.py firebase verify
"""
        )
        return

    cloud_type = sys.argv[1]
    command = sys.argv[2] if len(sys.argv) > 2 else "migrate"

    try:
        migration = CCBCloudMigration(cloud_type)

        if command == "migrate":
            migration.migrate_to_cloud(batch_size=100, dry_run=False)
            migration.verify_migration()

        elif command == "dry-run":
            migration.migrate_to_cloud(batch_size=100, dry_run=True)

        elif command == "verify":
            migration.verify_migration()

    except (RuntimeError, ValueError, TypeError, OSError, sqlite3.Error) as e:
        _emit(f"\nâŒ é”™è¯¯: {e}")
        return


if __name__ == "__main__":
    main()
